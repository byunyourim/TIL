## 가상 메모리
메모리가 실제 메모리보다 많아보이게 하는 기술로, 어떤 프로세스가 실행될 때 메모리에 해당 프로세스 전체가 올라가지 
않더라도 실행이 가능하다는 점에 착안하여 고안된 메모리 기법이다.  


<br>

### 왜 가상 메모리를 사용하는가?
물리 메모리는 컴퓨터에 장착된 실제 메모리로서 최대 크기는 CPU에 의해 제한된다. 

- 그렇다면 운영체제는 물리메모리보다 큰 프로세스를 실행시킬 수 없나?

- 또한 운영체제는 여러 프로세스를 합쳐 물리 메모리보다 클 때 이들을 동시에 실행 시킬 수 없나?

어떻게 한정된 메모리에서 여러 프로세스를 실행시킬 수 있도록 할 것인가?


<br><br>
  

프로세스는 가상 주소를 사용하고, 데이터를 사용할 때 물리 주소로 변환해 준다.
 
가상 메모리는 물리 메모리보다 큰 프로세스나 여러 개의 작은 프로세스를 동시에 실행시켜, 사용자나 응용프로그램에게 무한대의 메모리가 있다고 느끼도록하는 것이다.


운영체제는 가상 메모리 기법을 통해 프로그램의 실행에 필요한 부분만 물리적 메모리에 적재하고, 
직접적으로 필요하지 않은 메모리 공간은 디스크에 저장한다.

즉, 애플리케이션이 실행될 때, 실행에 필요한 일부분만 메모리에 올라가며 애플리케이션의 나머지는 디스크에 남게 된다.
따라서, 디스크가 RAM의 보조 기억장치(backing store)처럼 동작한다.    
  
결국 빠르고 작은 기억장치(RAM)을 크고 느린 기억장치(디스크)와 병합하여, 하나의 크고 빠른 기억장치(가상 메모리)처럼 동작한다.

  
가상 메모리를 구현하기 위해서는 
컴퓨터가 특수 메모리 관리 하드웨어를 갖추고 있어야 하는데 바로 MMU(Memory Management Unit)이다.



<br><br>

### MMU (Memory Management Unit)
- CPU가 가상 주소에 접근할 때, 이를 물리 주소로 변환하여 물리 메모리에 접근할 수 있도록 해주는 하드웨어 장치이다.  
- MMU를 사용하게 되면, CPU가 각 메모리에 접근하기 이전에 메모리 주소 번역 작업이 수행된다.
- 그러나 메모리를 일일이 가상 주소에서 물리적 주소로 번역하게 되면 작업 부하가 너무 높아지므로, MMU는 RAM을 여러 부분(페이지, pages)로 나누어 각 페이지를 하나의 독립된 항목으로 처리함.
페이지 및 주소 번역 정보를 기억하는 작업이 가상 메모리를 구현하는 데 있어 결정적인 절차임.
<img width="579" alt="스크린샷 2024-10-24 오후 12 23 01" src="https://github.com/user-attachments/assets/d52ed893-4564-426b-a05e-5120d48a5f3d">


<br>




> ### 가상 주소
> - 가상주소 : 프로그램/프로세스 내에서 사용하는 주소로 논리주소라고도 한다. (프로세스가 참조하는 주소)
> - 물리주소 : 실제 메모리 주소
> 컴파일러 입장에서 보면 프로그램 내에서 코드와 변수의 주소는 프로그램의 내에서의 상대적인 주소이므로 논리 주소라고 부르는 것이 적합하지만,
> 가상 메모리를 다루는 운영체제 입장에서는 프로세스의 가상 주소 공간 내에서 사용되는 주소를 가상 주소라고 부르는 것이 더 적합하다.


<br>



### 가상(논리) 주소 공간
가상 주소 공간은 각 프로세스 당 주어지는 논리적인 공간으로 물리 메모리(RAM)의 크기와는 독립적이며, 
레지스터 크기에 종속적이다.


#### 가상 주소 공간 구조 (프로세스 당)
- Stack : 지역변수, 함수의 매개변수 (함수 실행 시 저장, 종료 시 반환)
- Unused Address Space : 필요할 경우 (런타임 간 저장, 원할 때 반환)
- Heap : 사용자의 동적 할당 (런타임 간 저장, 원할 때 반환)
- Data and BSS : 초기화된 변수(Data), 초기화 안 된 변수(BSS) (컴파일 시 저장, 프로그램 종료 시 반환)
- Instruction(Code or Text) : 실행할 코드 (기계어 형태) (컴파일 시 저장, 프로그램 종료 시 반환)



 


<br><br><br>

## 페이징 시스템 
가상 메모리 시스템을 구현하는 다양한 방법으로 가장 많이 사용되는 방법이다.  

- paging: 크기가 동일한 page로 가상 주소 공간과 이에 매핑되는 물리 주소 공간을 관리한다.
- page(page frame): 고정된 동일한 크기의 block
- paging table: 물리 메모리에 있는 page frame 번호와 해당 페이지의 첫 물리 주소 정보를 매핑한 표



### 1) 다중 단계 페이징 시스템


### 2) 페이징 시스템과 공유 메모리







<br><br><br>



## 요구 페이징(demand paging)이란?
요구 페이징은 CPU가 요청할 때 프로세스의 데이터를 메모리에 올리는 것을 의미함. 즉, 처음부터 모든 데이터를 메모리로 적재하지는 않음.
  
  
이 때 valid/Invalid bit가 사용된다. 

- Invalid: 사용되지 않는 주소 영역인 경우, 페이지가 물리적 메모리에 없는 경우 (valid는 반대)   
처음에는 모든 page가 invalid로 초기화되고, 사용되면 valid로 되는데, address translation시에 invalid bit이라면 page fault가 발생한다.

- page fault:  어떤 페이지가 물리 메모리에 없을 때 발생하는 인터럽트로, page fault가 발생하면 운영체제가 해당 페이지를 물리 메모리에 올려준다. 

<br><br><br>


## 페이지 폴트(page faults)란?
페이지 폴트란 어떤 페이지에 접근하려고 했을 때 해당 페이지가 실제 물리 메모리에 부재할 때 뜨는 인터럽트이며, 페이지 폴트가 발생하면 운영체제가 이를 해결한 뒤 다시 동일한 명령을 수행하는 식으로 동작함.

- 페이지 폴트란, 어떤 프로그램이 자신의 주소 공간(가상 메모리 공간)에는 존재하지만 시스템의 RAM에는 현재 존재하지 않는 데이터·코드에 접근을 시도할 경우 발생하는 현상을 의미함.
- 페이지 폴트가 발생하면 운영체제는 그 데이터를 메모리로 가져와서, 마치 페이지 폴트가 전혀 발생하지 않은 것처럼 프로그램이 계속적으로 작동하게 해줌.
- 이러한 페이지 폴트가 자주 일어날수록 운영체제의 성능이 많이 저하되기 때문에 페이지 폴트가 일어나지 않도록 하는 것이 중요함. 페이지 폴트를 최소화하기 위한 방법으로는 페이지 교체 정책(page replacement policy)이 있음.
- 메모리가 꽉 차있을 때 기존 페이지 중 하나를 물리 메모리에서 저장 매체로 내리고, 새로운 페이지를 방금 비워진 해당 물리 메모리 공간에 올림. 이때 기존 페이지 중 어떤 것을 내리면 좋을지에 대한 알고리즘을 짠 것이 바로 페이지 교체 알고리즘인 것!

<br><br><br>



## 페이지 교체 정책(Page replacement policy) 
영체제가 특정 페이지를 물리 메모리에 올리려고 하는데 물리 메모리가 다 차있다면? 기존 페이지 중 하나르 물리 메모리에서 저장 매체로 내리고(저장) 새로운 페이지를 해당 물리 메모리 공간에 올려야한다. 이 때 어떤 페이지를 물리 메모리에서, 저장 매체로 내릴 것인가에 대한 것이 페이지 교체 정책이다.

### 1) FIFO 알고리즘

가장 먼저 들어온 페이지를 내린다. 

### 2) OPT(OPTimal) 알고리즘

앞으로 가장 오랫동안 사용하지 않을 페이지를 내린다.   
=> 그러나 미래에 어떤 페이지를 얼마나 사용할 것인지는 알 수 없으므로 일반 OS에서는 구현이 불가하다. 

### 3) LRU(Least Recently Used) 알고리즘

가장 오래전에 사용된 페이지를 내리자 라는 아이디어로,  
OPT 알고리즘이 미래의 일을 알 수 없으므로 구현이 불가하므로, LRU에서는 과거 기록을 기반으로 시도한 것이다. 

### 4) LFU(Least Frequently Used) 알고리즘

가장 적게 사용된 페이지를 내리자. 

### 5) NUR(Not Used Recently) 알고리즘

LRU와 마찬가지로 최근에 사용하지 않은 페이지부터 내리자는 알고리즘인데,   
각 페이지마다 참조 여부를 나타내는 비트(R), 수정 여부를 나타내는 비트(M)을 두어서 (0, 0), (0, 1), (1, 0), (1, 1) 순으로 교체한다. 

<br><br><br>

# TLB(Translation Lookaside Buffer, 페이지 정보 캐쉬)란?
TLB는 가상 메모리 주소를 물리적 주소로 변환하는 속도를 높이기 위해 사용하는 캐시이다.  

최근에 일어난 가상 메모리와 물리 주소의 변환 테이블을 저장해두고, CPU가 가상 주소를 가지고 메모리에 접근하려고 할 때,  
먼저 TLB에 접근하여 가상 주소에 해당되는 물리 주소를 찾고, 만약 TLB에 매핑이 존재하지 않는다면 MMU가 페이지 테이블에서 해당되는 물리 주소로 변환한 후 메모리에 접근한다.
   
TLB는 MMU에 포함되어 있는 작은 캐시로, **일종의 주소 변환 캐시**라고 할 수 있다.  

> #### 캐시 메모리(cache memory)란?
> 속도가 빠른 장치와 느린 장치 사이에서 속도 차에 따른 병목 현상을 줄이기 위한 범용 메모리
> CPU에서의 캐시 메모리는 CPU 코어(고속)와 메모리(CPU에 비해 저속) 사이에서 속도 차에 따른 병목 현상을 완화하는 역할을 함.
> 또한, 인터넷 웹 브라우저에는 캐시 파일이라는 개념이 있는데 캐시 파일은 웹 페이지 상의 이미지 등을 하드디스크에 미리 저장해두고, 다음 번에도 해당 웹 페이지에 접근할 때 하드디스크에서 이미지를 불러들여 로딩 속도를 높이는 역할을 한다.
> 즉 캐시 파일은 비교적 속도가 빠른 하드디스크과 상대적으로 느린 웹 페이지 가운데서의 병목을 줄이는 역할을 한다.  


#### TLB 사용 이점
메모리(RAM)에 두 번 들릴 필요없이, 바로 해당 물리주소(in 메모리)를 찾아갈 수 있다.

<img width="559" alt="스크린샷 2024-10-24 오후 12 57 50" src="https://github.com/user-attachments/assets/4cfee9f4-bdda-4259-ad57-6ba6a3cbad71">







